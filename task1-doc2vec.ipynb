{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Scott Sun\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import keras\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from gensim import corpora,models,utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLIEE_2018\n"
     ]
    }
   ],
   "source": [
    "# xml parsing\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse(\"./COLIEE2018_CaseLaw_Training_Data/IR/IR.xml\")\n",
    "root = tree.getroot()\n",
    "print(root.tag)\n",
    "\n",
    "cases_noticed_list = []\n",
    "for node in root.iter('cases_noticed'):\n",
    "    if node.text:\n",
    "        cases_noticed_list.append(list(node.text.split(',')))\n",
    "    else:\n",
    "        cases_noticed_list.append([0])\n",
    "# cases_noticed_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "word-vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_article_list=[]\n",
    "candidate_article_list_l=[]\n",
    "for no in range(1,286):\n",
    "        \n",
    "        if no<10:\n",
    "            nos = '00'+str(no)\n",
    "        elif no<100:\n",
    "            nos = '0'+str(no)\n",
    "        else:\n",
    "            nos = str(no)\n",
    "        target_articlef = open('./COLIEE2018_CaseLaw_Training_Data/IR/data/'+nos+'/fact.txt',encoding='utf-8')\n",
    "        target_article = target_articlef.read().replace('\\n','').replace('[','').replace(']','')\n",
    "        target_article_list.append(target_article)\n",
    "        \n",
    "        candidate_article_list = []\n",
    "        for i in range(200):\n",
    "            if i<10:\n",
    "                index = '00'+str(i)\n",
    "            elif i<100:\n",
    "                index = '0'+str(i)\n",
    "            else:\n",
    "                index = str(i)\n",
    "            candidate_articlef = open('./COLIEE2018_CaseLaw_Training_Data/IR/data/'+nos+'/candidates/'+index+'.txt',encoding='utf-8')\n",
    "            candidate_article = candidate_articlef.read().replace('\\n','').replace('[','').replace(']','')\n",
    "            candidate_article_list.append(candidate_article)\n",
    "        candidate_article_list_l.append(candidate_article_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_doc = Doc2Vec(vector_size=50, min_count=5, epochs=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n"
     ]
    }
   ],
   "source": [
    "target_train_list=[]\n",
    "tn = 1\n",
    "for ta in target_article_list:\n",
    "    target_train_list.append(models.doc2vec.TaggedDocument(utils.simple_preprocess(ta), 'target'+str(tn)))\n",
    "    tn+=1\n",
    "#     print(tn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n"
     ]
    }
   ],
   "source": [
    "can_train_list=[]\n",
    "casen = 1\n",
    "for candidate_article_list in candidate_article_list_l:\n",
    "    cn = 0\n",
    "    for candidate_article in candidate_article_list:\n",
    "        can_train_list.extend(models.doc2vec.TaggedDocument(utils.simple_preprocess(candidate_article), 'case'+str(casen)+'candidate'+str(cn)))\n",
    "        cn+=1\n",
    "    casen+=1\n",
    "    print(casen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus_target(tokens_only=False):\n",
    "    for index, content in zip(range(1,286),target_article_list):\n",
    "            if tokens_only:\n",
    "                yield utils.simple_preprocess(line)\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield models.doc2vec.TaggedDocument(utils.simple_preprocess(content), 'target'+str(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_train_list2 = list(read_corpus_target(tokens_only=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus_candidate(tokens_only=False):\n",
    "    for i in range(0,285):\n",
    "        for index, content in zip(range(1,286),candidate_article_list_l[i]):\n",
    "            if tokens_only:\n",
    "                yield utils.simple_preprocess(line)\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield models.doc2vec.TaggedDocument(utils.simple_preprocess(content), 'case'+str(i)+'candidate'+str(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-12f53f617c1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcan_train_list2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_corpus_candidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-6fc26d577cf4>\u001b[0m in \u001b[0;36mread_corpus_candidate\u001b[1;34m(tokens_only)\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                 \u001b[1;31m# For training data, add tags\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTaggedDocument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimple_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'case'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'candidate'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Scott Sun\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36msimple_preprocess\u001b[1;34m(doc, deacc, min_len, max_len)\u001b[0m\n\u001b[0;32m    303\u001b[0m     \"\"\"\n\u001b[0;32m    304\u001b[0m     tokens = [\n\u001b[1;32m--> 305\u001b[1;33m         \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeacc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeacc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmin_len\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m     ]\n",
      "\u001b[1;32mC:\\Users\\Scott Sun\\Anaconda3\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(text, lowercase, deacc, encoding, errors, to_lower, lower)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdeacc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeaccent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "can_train_list2 = list(read_corpus_candidate(tokens_only=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_list = target_train_list2+can_train_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_doc.build_vocab(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time model_doc.train(train_list, total_examples=model_doc.corpus_count, epochs=model_doc.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "fname = get_tmpfile(\"my_doc2vec_model\")\n",
    "model_doc.save(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_doc_train = Doc2Vec.load(\"my_doc2vec_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-eb41428c9649>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvectors1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvectors1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_doc_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_list' is not defined"
     ]
    }
   ],
   "source": [
    "vectors1 = dict()\n",
    "for i in train_list:\n",
    "    name = i[1]\n",
    "    vectors1[name]=model_doc_train.infer_vector(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57285, 50)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame.from_dict(vectors1).transpose()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "#split\n",
    "rem = random.sample(range(286),86)\n",
    "# rem\n",
    "data.to_csv('data_t1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3701"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cases_noticed_list[0]\n",
    "# can_train_list2[0]\n",
    "# candidate_article_list_l[0][18]\n",
    "# cases_noticed_list[53]\n",
    "# len(score)\n",
    "# len(dataset)\n",
    "# len(pred)\n",
    "# for rpa in cases_noticed_list[20]:\n",
    "#     string_l = [target_article_list[20]+candidate_article_list_l[20][int(rpa)]]\n",
    "#     count = CountVectorizer(min_df=0,ngram_range=(2,3))\n",
    "#     count.fit(string_l)\n",
    "#     count1 = count.transform([target_article_list[20]]).todense()\n",
    "#     A = count.transform([candidate_article_list_l[20][int(rpa)]]).todense()\n",
    "#     B = np.matmul(count1,A.T).T\n",
    "#     C = np.sum(A) + np.sum(count1)-B\n",
    "#     D = B / C\n",
    "# cases_noticed_list[20]\n",
    "# rem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training\n",
    "import random\n",
    "pred = []\n",
    "dataset = dict()\n",
    "score = []\n",
    "for index in range(len(cases_noticed_list)):\n",
    "    if index == 53:\n",
    "        continue\n",
    "    if index in rem:\n",
    "#         print(index)\n",
    "        continue\n",
    "    n=1\n",
    "    case = 'target'+str(index+1)\n",
    "    seq = []\n",
    "    for i in range(200):\n",
    "        seq.append(str(i))\n",
    "    for rpa in cases_noticed_list[index]:\n",
    "#         rpa = str(rpa).replace(' ','')\n",
    "#         print(rpa)\n",
    "        seq.remove(rpa)\n",
    "        para = 'case'+str(index) + 'candidate'+str(int(rpa)+1)\n",
    "        temp = data.loc[case,:].tolist()\n",
    "        for i in data.loc[para,:].tolist():\n",
    "            temp.append(i)\n",
    "        dataset[case+'-'+str(n)]=temp\n",
    "        n+=1\n",
    "        pred.append(1)\n",
    "        \n",
    "        string_l = [target_article_list[index]+candidate_article_list_l[index][int(rpa)]]\n",
    "        \n",
    "        count = CountVectorizer(min_df=0,ngram_range=(2,3),stop_words='english')\n",
    "        count.fit(string_l)\n",
    "        count1 = count.transform([target_article_list[index]]).todense()\n",
    "        A = count.transform([candidate_article_list_l[index][int(rpa)]]).todense()\n",
    "        B = np.matmul(count1,A.T).T\n",
    "        C = np.sum(A, axis = 1) + np.sum(count1)-B\n",
    "        D = B / C\n",
    "        score.append(D[0,0])\n",
    "#     print(index,':',len(dataset),',',len(score))    \n",
    "    candi = random.sample(seq,len(cases_noticed_list[index]))\n",
    "    for num in candi:\n",
    "        para = 'case'+str(index) + 'candidate'+str(int(num)+1)\n",
    "        temp = data.loc[case,:].tolist()\n",
    "        for i in data.loc[para,:].tolist():\n",
    "            temp.append(i)\n",
    "        dataset[case+'-'+str(n)]=temp\n",
    "        n+=1\n",
    "        pred.append(0)\n",
    "        \n",
    "        string_l = [target_article_list[index]+candidate_article_list_l[index][int(num)]]\n",
    "        count = CountVectorizer(min_df=0,ngram_range=(2,3),stop_words='english')\n",
    "        count.fit(string_l)\n",
    "        count1 = count.transform([target_article_list[index]]).todense()\n",
    "        A = count.transform([candidate_article_list_l[index][int(num)]]).todense()\n",
    "        B = np.matmul(count1,A.T).T\n",
    "        C = np.sum(A, axis = 1) + np.sum(count1)-B\n",
    "        D = B / C\n",
    "        score.append(D[0,0])\n",
    "    if len(dataset) != len(score):\n",
    "        print(index,':',len(dataset),',',len(score))\n",
    "#     print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data2 = pd.DataFrame.from_dict(dataset).transpose()\n",
    "data2['score'] = score\n",
    "data2.to_csv('data2_t1.csv')\n",
    "# data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = data2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth=50, random_state=0, n_estimators=100)\n",
    "rf.fit(train_x,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_rf = []\n",
    "for index in range(len(cases_noticed_list)):\n",
    "    result_t=[]\n",
    "    if index not in rem:\n",
    "#         print(index)\n",
    "        continue\n",
    "    case = 'target'+str(index+1)\n",
    "    for rpa in range(len(candidate_article_list_l[index])):\n",
    "        temp = data.loc[case,:].tolist()\n",
    "        para = 'case'+str(index) + 'candidate'+str(rpa+1)\n",
    "        for i in data.loc[para,:].tolist():\n",
    "            temp.append(i)\n",
    "#         print(rf.predict_proba([temp])[0][0])\n",
    "\n",
    "        string_l = [target_article_list[index]+candidate_article_list_l[index][rpa]]\n",
    "        count = CountVectorizer(min_df=0,ngram_range=(2,3))\n",
    "        count.fit(string_l)\n",
    "        count1 = count.transform([target_article_list[index]]).todense()\n",
    "        A = count.transform([candidate_article_list_l[index][rpa]]).todense()\n",
    "        B = np.matmul(count1,A.T).T\n",
    "        C = np.sum(A, axis = 1) + np.sum(count1)-B\n",
    "        D = B / C\n",
    "        temp.append(D[0,0])\n",
    "        result_t.append(rf.predict_proba([temp])[0][0])\n",
    "    result_rf.append(np.argsort(result_t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([142, 191,  41,  32, 143, 190,  99, 194, 140, 150,  21, 175,  58,\n",
       "         1, 122, 182, 131,  55, 129,  16, 146, 149, 162, 197, 172,  59,\n",
       "        70,  76,  80,  25, 126, 137, 145, 195,  98, 117,  84, 152,  75,\n",
       "       193, 111, 102, 199,  31,  12, 151,  29, 158,  92,  49, 183,  67,\n",
       "        60,  18,  57,  72,  79,  63, 156, 104, 135, 100, 101, 105, 153,\n",
       "        53,  86, 176,  34,  87, 164,  78,  11,  77,  95, 106, 170, 148,\n",
       "        44, 181,  48, 180, 138, 110,  54, 127,   6, 192,  28,  64, 173,\n",
       "       115,  69, 124, 155, 136, 198,  43, 133,  94, 179,  71,  73, 166,\n",
       "       177,  81, 174,  85,  47,  46,  33,  52, 128, 125,  51, 123, 141,\n",
       "        26,   5,  10, 171,  35, 107,  90,  61,  88, 157, 178,  19,  15,\n",
       "       167, 134, 160, 159, 113, 184,  93,  40,  96,  56,  30,  42, 196,\n",
       "        37,  66, 188,   4,  74, 112, 185,  17, 144,   7, 139,  45, 161,\n",
       "        83,  38, 168,  39, 165,  50, 163,  91,  97, 154, 109,  13, 130,\n",
       "        14, 120, 189,  23, 108, 187,   3, 147, 114,  20,   8,  82, 186,\n",
       "        65,  62,   2, 121, 169,  24,  89,  27,  22, 118, 103,  36,  68,\n",
       "         9,   0, 132, 116, 119], dtype=int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_rf[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of prediction:  1\n",
      "precision:  0.022099447513812154\n",
      "recall:  0.002212336466480113\n",
      "F2-measure:  0.002697900085822389\n",
      "num of prediction:  2\n",
      "precision:  0.024861878453038673\n",
      "recall:  0.00528006612624234\n",
      "F2-measure:  0.0062673252992125365\n",
      "num of prediction:  3\n",
      "precision:  0.025782688766114177\n",
      "recall:  0.008176433111007115\n",
      "F2-measure:  0.009469758133936827\n",
      "num of prediction:  4\n",
      "precision:  0.024861878453038673\n",
      "recall:  0.011076177868850156\n",
      "F2-measure:  0.012457717603859081\n",
      "num of prediction:  5\n",
      "precision:  0.026519337016574593\n",
      "recall:  0.01813214041021128\n",
      "F2-measure:  0.01935650602333743\n",
      "num of prediction:  6\n",
      "precision:  0.027624309392265192\n",
      "recall:  0.020253895047751238\n",
      "F2-measure:  0.021395602929010778\n",
      "num of prediction:  7\n",
      "precision:  0.025256511444356748\n",
      "recall:  0.021504258525506397\n",
      "F2-measure:  0.02216278473483135\n",
      "num of prediction:  8\n",
      "precision:  0.024171270718232045\n",
      "recall:  0.02219757452593972\n",
      "F2-measure:  0.02256609983718827\n",
      "num of prediction:  9\n",
      "precision:  0.02209944751381216\n",
      "recall:  0.022448704611323946\n",
      "F2-measure:  0.0223779728354655\n",
      "num of prediction:  10\n",
      "precision:  0.020994475138121558\n",
      "recall:  0.0231351268447075\n",
      "F2-measure:  0.02267277179821478\n",
      "num of prediction:  11\n",
      "precision:  0.020592667001506772\n",
      "recall:  0.02532553925611439\n",
      "F2-measure:  0.024212570237748827\n",
      "num of prediction:  12\n",
      "precision:  0.0207182320441989\n",
      "recall:  0.026520034856687337\n",
      "F2-measure:  0.02511350916662329\n",
      "num of prediction:  13\n",
      "precision:  0.02209944751381217\n",
      "recall:  0.030882223368130204\n",
      "F2-measure:  0.02860831646670703\n",
      "num of prediction:  14\n",
      "precision:  0.021704814522494096\n",
      "recall:  0.03290800605689632\n",
      "F2-measure:  0.02982871833160081\n",
      "num of prediction:  15\n",
      "precision:  0.02062615101289136\n",
      "recall:  0.03302075834013005\n",
      "F2-measure:  0.029477992277333654\n",
      "num of prediction:  16\n",
      "precision:  0.020027624309392266\n",
      "recall:  0.03424850542423073\n",
      "F2-measure:  0.029989602210119575\n",
      "num of prediction:  17\n",
      "precision:  0.021449463763405893\n",
      "recall:  0.03778300477562038\n",
      "F2-measure:  0.032789268213825926\n",
      "num of prediction:  18\n",
      "precision:  0.02117863720073663\n",
      "recall:  0.0404687015220906\n",
      "F2-measure:  0.03423269268435976\n",
      "num of prediction:  19\n",
      "precision:  0.021808665309683055\n",
      "recall:  0.04333815646700353\n",
      "F2-measure:  0.03619234715672518\n",
      "num of prediction:  20\n",
      "precision:  0.021270718232044187\n",
      "recall:  0.04414177274023306\n",
      "F2-measure:  0.03632926232313733\n",
      "num of prediction:  21\n",
      "precision:  0.021310181531176\n",
      "recall:  0.046449215054175215\n",
      "F2-measure:  0.03758226315252771\n",
      "num of prediction:  22\n",
      "precision:  0.021094927172275228\n",
      "recall:  0.04779474361691808\n",
      "F2-measure:  0.038139996732581144\n",
      "num of prediction:  23\n",
      "precision:  0.021619024741772772\n",
      "recall:  0.05017436215675762\n",
      "F2-measure:  0.03968961275170923\n",
      "num of prediction:  24\n",
      "precision:  0.021869244935543278\n",
      "recall:  0.05321303618990679\n",
      "F2-measure:  0.04135790711555562\n",
      "num of prediction:  25\n",
      "precision:  0.021436464088397802\n",
      "recall:  0.054206926686559714\n",
      "F2-measure:  0.04151417399557833\n",
      "num of prediction:  26\n",
      "precision:  0.021036974075648113\n",
      "recall:  0.05464467084499657\n",
      "F2-measure:  0.041412827342407366\n",
      "num of prediction:  27\n",
      "precision:  0.0216901984857786\n",
      "recall:  0.0572987989877732\n",
      "F2-measure:  0.043135701613351535\n",
      "num of prediction:  28\n",
      "precision:  0.021902131018153123\n",
      "recall:  0.060840672794051094\n",
      "F2-measure:  0.044882034220931934\n",
      "num of prediction:  29\n",
      "precision:  0.022099447513812154\n",
      "recall:  0.06230508428317906\n",
      "F2-measure:  0.04568286922211214\n",
      "num of prediction:  30\n",
      "precision:  0.02154696132596686\n",
      "recall:  0.06244320583014039\n",
      "F2-measure:  0.04526178516622131\n",
      "num of prediction:  31\n",
      "precision:  0.022099447513812143\n",
      "recall:  0.06439601223606856\n",
      "F2-measure:  0.0465698304240274\n",
      "num of prediction:  32\n",
      "precision:  0.02227209944751381\n",
      "recall:  0.06687526170987625\n",
      "F2-measure:  0.04774998496946433\n",
      "num of prediction:  33\n",
      "precision:  0.022099447513812143\n",
      "recall:  0.06798023408556685\n",
      "F2-measure:  0.04803506194060337\n",
      "num of prediction:  34\n",
      "precision:  0.022586935326616812\n",
      "recall:  0.07058366680676637\n",
      "F2-measure:  0.04953255352610075\n",
      "num of prediction:  35\n",
      "precision:  0.022257300710339368\n",
      "recall:  0.07150447711984188\n",
      "F2-measure:  0.0495689331290656\n",
      "num of prediction:  36\n",
      "precision:  0.022866789441375063\n",
      "recall:  0.07374982129029864\n",
      "F2-measure:  0.05103657155644826\n",
      "num of prediction:  37\n",
      "precision:  0.02284605047035987\n",
      "recall:  0.07483688902101279\n",
      "F2-measure:  0.051429314244548587\n",
      "num of prediction:  38\n",
      "precision:  0.022971794126199478\n",
      "recall:  0.07693448345808444\n",
      "F2-measure:  0.052342901840711206\n",
      "num of prediction:  39\n",
      "precision:  0.023232752514520456\n",
      "recall:  0.08081494864741164\n",
      "F2-measure:  0.054031579076366444\n",
      "num of prediction:  40\n",
      "precision:  0.023618784530386742\n",
      "recall:  0.08454934602821787\n",
      "F2-measure:  0.05577317525894993\n",
      "num of prediction:  41\n",
      "precision:  0.023446974801239737\n",
      "recall:  0.08535541431188493\n",
      "F2-measure:  0.055858245815353015\n",
      "num of prediction:  42\n",
      "precision:  0.02367797947908444\n",
      "recall:  0.09361878997857553\n",
      "F2-measure:  0.05885136345386454\n",
      "num of prediction:  43\n",
      "precision:  0.02402672491327253\n",
      "recall:  0.0954296723231776\n",
      "F2-measure:  0.05985443045719806\n",
      "num of prediction:  44\n",
      "precision:  0.023731793068809647\n",
      "recall:  0.09615629814846169\n",
      "F2-measure:  0.05971111380963863\n",
      "num of prediction:  45\n",
      "precision:  0.02418661755678329\n",
      "recall:  0.10168176233612002\n",
      "F2-measure:  0.061970463233842\n",
      "num of prediction:  46\n",
      "precision:  0.023780927215950032\n",
      "recall:  0.10181988388308136\n",
      "F2-measure:  0.06147372488710686\n",
      "num of prediction:  47\n",
      "precision:  0.02339250029387562\n",
      "recall:  0.10193263616631508\n",
      "F2-measure:  0.06098278913002704\n",
      "num of prediction:  48\n",
      "precision:  0.023480662983425403\n",
      "recall:  0.10467636717621445\n",
      "F2-measure:  0.06188022758142774\n",
      "num of prediction:  49\n",
      "precision:  0.023452474912616966\n",
      "recall:  0.10589680010076545\n",
      "F2-measure:  0.062179737855146196\n",
      "num of prediction:  50\n",
      "precision:  0.02375690607734806\n",
      "recall:  0.108544864798637\n",
      "F2-measure:  0.06333591954144739\n"
     ]
    }
   ],
   "source": [
    "for num in range(1,51):\n",
    "    precision = []\n",
    "    recall = []\n",
    "    for j in range(len(result_rf)):\n",
    "        r = result_rf[j][-num:]\n",
    "        prtop = 0\n",
    "        for re in r:\n",
    "            if str(re+1) in cases_noticed_list[rem[j]]:\n",
    "                prtop+=1\n",
    "        precision.append(prtop)\n",
    "        recall.append(len(cases_noticed_list[rem[j]]))\n",
    "    \n",
    "    pre = 0.0\n",
    "    rec = 0.0\n",
    "    for i in range(len(precision)):\n",
    "        pre+= precision[i]/num\n",
    "        rec+= precision[i]/recall[i]\n",
    "        \n",
    "    pre = pre/181\n",
    "    rec = rec/181\n",
    "    F2 = 5*pre*rec/(4*pre+rec)\n",
    "    \n",
    "    print('num of prediction: ',num)\n",
    "    print('precision: ',pre)\n",
    "    print('recall: ',rec)\n",
    "    print('F2-measure: ',F2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
